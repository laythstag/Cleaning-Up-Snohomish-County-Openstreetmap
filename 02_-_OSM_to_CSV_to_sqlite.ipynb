{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "OSM_PATH = \"Snohomish_County.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    ndloc = 0\n",
    "    if element.tag == 'node':\n",
    "        for att in node_attr_fields:\n",
    "            if att == 'version' or att == 'timestamp':\n",
    "                node_attribs[att] = element.attrib[att]\n",
    "            elif att == 'user':\n",
    "                try:\n",
    "                    if element.attrib[att].decode('utf-8'):\n",
    "                        node_attribs[att] = element.attrib[att]\n",
    "                except:\n",
    "                    node_attribs[att] = element.attrib[att].encode('utf-8').decode('utf-8')\n",
    "            elif att == 'lat' or att == 'lon':\n",
    "                node_attribs[att] = float(element.attrib[att])\n",
    "            elif att == 'id' or att == 'uid' or att == 'version' or att == 'changeset':\n",
    "                node_attribs[att] = int(element.attrib[att])\n",
    "        for child in element:\n",
    "            if child.tag == 'tag' and problem_chars.search(child.attrib['k']) == None:\n",
    "                tags.append({})\n",
    "                if ':' in child.attrib['k']:\n",
    "                    coloc = child.attrib['k'].find(':')\n",
    "                    tags[-1]['key'] = child.attrib['k'][coloc+1:]\n",
    "                    tags[-1]['id'] = int(element.attrib['id'])\n",
    "                    if child.attrib['k'][coloc+1:] in common_mistakes:\n",
    "                        tags[-1]['value'] = fix_values(child.attrib['k'][coloc+1:], child.attrib['v'])\n",
    "                    elif child.attrib['k'][coloc+1:] == 'postal_code':\n",
    "                        tags[-1]['value'] = fix_post(child.attrib['v'])\n",
    "                    else:\n",
    "                        tags[-1]['value'] = child.attrib['v']\n",
    "                    tags[-1]['type'] = child.attrib['k'][:coloc]\n",
    "                else:\n",
    "                    tags[-1]['key'] = child.attrib['k'] \n",
    "                    tags[-1]['id'] = int(element.attrib['id'])\n",
    "                    if child.attrib['k'] in common_mistakes:\n",
    "                        tags[-1]['value'] = fix_values(child.attrib['k'], child.attrib['v'])\n",
    "                    elif child.attrib['k'] == 'postal_code':\n",
    "                        tags[-1]['value'] = fix_post(child.attrib['v'])\n",
    "                    else:\n",
    "                        tags[-1]['value'] = child.attrib['v']\n",
    "                    tags[-1]['type'] = default_tag_type\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for att in way_attr_fields:\n",
    "            if att == 'user' or att == 'version' or att == 'timestamp':\n",
    "                way_attribs[att] = element.attrib[att]\n",
    "            elif att == 'id' or att == 'uid' or att == 'version' or att == 'changeset':\n",
    "                way_attribs[att] = int(element.attrib[att])\n",
    "        for child in element:\n",
    "            if child.tag == 'tag' and problem_chars.search(child.attrib['k']) == None:\n",
    "                tags.append({})\n",
    "                if ':' in child.attrib['k']:\n",
    "                    coloc = child.attrib['k'].find(':')\n",
    "                    new_key = replace_keys(child.attrib['k'][coloc+1:])\n",
    "                    tags[-1]['key'] = new_key\n",
    "                    tags[-1]['id'] = int(element.attrib['id'])\n",
    "                    if new_key in common_mistakes:\n",
    "                        tags[-1]['value'] = fix_values(new_key, child.attrib['v'])\n",
    "                    elif new_key == 'postal_code':\n",
    "                        tags[-1]['value'] = fix_post(child.attrib['v'])\n",
    "                    else:\n",
    "                        tags[-1]['value'] = child.attrib['v']\n",
    "                    tags[-1]['type'] = child.attrib['k'][:coloc]\n",
    "                else:\n",
    "                    new_key = replace_keys(child.attrib['k'])\n",
    "                    tags[-1]['key'] = new_key\n",
    "                    tags[-1]['id'] = int(element.attrib['id'])\n",
    "                    if new_key in common_mistakes:\n",
    "                        tags[-1]['value'] = fix_values(new_key, child.attrib['v'])\n",
    "                    elif new_key == 'postal_code':\n",
    "                        tags[-1]['value'] = fix_post(child.attrib['v'])\n",
    "                    else:\n",
    "                        tags[-1]['value'] = child.attrib['v']\n",
    "                    tags[-1]['type'] = default_tag_type \n",
    "            elif child.tag == 'nd':\n",
    "                way_nodes.append({})\n",
    "                way_nodes[-1]['id'] = int(element.attrib['id'])\n",
    "                way_nodes[-1]['node_id'] = int(child.attrib['ref'])\n",
    "                way_nodes[-1]['position'] = ndloc\n",
    "                ndloc += 1\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "# ================================================== #\n",
    "#               Fixer Functions                      #\n",
    "# ================================================== #\n",
    "    \n",
    "replace = {'County': 'county', 'FIXME': 'fixme', 'Elevation': 'elevation', 'fixeme': 'fixme', 'ST_alph': 'ST_alpha', \n",
    "           'COUNTYFP': 'County_num', 'postcode': 'postal_code', 'county_name': 'county', 'state_id': 'ST_num', \n",
    "           'state_code': 'ST_alpha', 'STATEFP': 'ST_num'}\n",
    "def replace_keys(old_key):\n",
    "    if old_key in replace:\n",
    "        return replace[old_key]\n",
    "    else:\n",
    "        return old_key\n",
    "    \n",
    "common_mistakes = {'city':\n",
    "                   {'Kirkalnd': 'Kirkland', 'Tulalip': 'Tulalip Indian Reservation', 'kenmore': 'Kenmore', \n",
    "                    'Port Gamble': 'Port Gamble Tribal Comunity', 'EDMONDS': 'Edmonds', 'Granite Fall': 'Granite Falls', \n",
    "                    'seattle': 'Seattle', 'BOTHELL': 'Bothell', 'Remond': 'Redmond', 'SILVERDALE': 'Silverdale', \n",
    "                    'Greenbank (Whidbey Island)': 'Greenbank', 'everett': 'Everett', 'goldbar': 'Gold Bar', \n",
    "                    'Oak Harbor (Whidbey Island)': 'Oak Harbor', 'marysville': 'Marysville', 'Lynwood': 'Lynnwood', \n",
    "                    'Woodenville': 'Woodinville', 'Camano Island': 'Camano', 'coupeville': 'Coupeville', \n",
    "                    'EVERETT': 'Everett', 'leavenworth': 'Leavenworth', 'Lake Stephens': 'Lake Stevens', \n",
    "                    'Mt. Vernon': 'Mount Vernon', 'Coupeville (Whidbey Island)': 'Coupeville', 'Bothel': \n",
    "                    'Bothell', 'woodinville': 'Woodinville'},\n",
    "                   'county':\n",
    "                   {'King, WA:Snohomish, WA': 'King;Snohomish', 'King, WA;Chelan, WA': 'King;Chelan'},\n",
    "                   'state':\n",
    "                   {'wa': 'State of Washington', 'w': 'State of Washington', 'Wa': 'State of Washington', \n",
    "                    '98107': 'State of Washington', 'Washington': 'State of Washington', 'W': 'State of Washington', \n",
    "                    'WA': 'State of Washington'},\n",
    "                   'country':\n",
    "                   {'US': 'USA'}}\n",
    "\n",
    "def fix_values(key, old_value):\n",
    "    if old_value in common_mistakes[key]:\n",
    "        return common_mistakes[key][old_value]\n",
    "    else:\n",
    "        return old_value\n",
    "\n",
    "def fix_post(old_value):\n",
    "    if '-' in old_value:\n",
    "        return old_value.split('-')[0]\n",
    "    else:\n",
    "        return old_value\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        print True\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, codecs.open(WAYS_PATH, 'w') as ways_file, codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        #validator = cerberus.Validator()\n",
    "        x = 0\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                #if validate is True:\n",
    "                #    validate_element(el, validator)\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['nodes.csv','ways.csv', 'ways_tags.csv', 'nodes_tags.csv', 'ways_nodes.csv']\n",
    "    \n",
    "for filename in files:\n",
    "    with open('{}_{}'.format('new',filename), 'w') as f_out:\n",
    "        for line in open(filename):\n",
    "            line = line.rstrip()\n",
    "            if line != '':\n",
    "                line = line + '\\n'\n",
    "                f_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts CSV files to sqlite3\n",
    "\n",
    "csv_files = ['new_nodes.csv', 'new_ways.csv', 'new_nodes_tags.csv', 'new_ways_tags.csv', 'new_ways_nodes.csv']\n",
    "con = sqlite3.connect(\"final_county.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "for csv_file in csv_files: #go over each csv file\n",
    "    splitcsv = csv_file.split('.')[0]\n",
    "    keys = []\n",
    "    \n",
    "    with open(csv_file,'rb') as fin: #just looking for the headers or keys\n",
    "        dr = csv.DictReader(fin)\n",
    "        for f in dr:\n",
    "            for key in f:\n",
    "                keys.append(key)\n",
    "            break\n",
    "        \n",
    "    key_string = '' #creates a string of keys for later use\n",
    "    for key in keys:\n",
    "        if key_string == '':\n",
    "            key_string = key_string + key\n",
    "        else:\n",
    "            key_string = key_string + ', ' + key\n",
    "            \n",
    "    question_marks = '' #creates a string of question marks for later use\n",
    "    for n in range(len(keys)):\n",
    "        if question_marks == '':\n",
    "            question_marks = question_marks + '?'\n",
    "        else:\n",
    "            question_marks = question_marks + ', ' + '?'\n",
    "            \n",
    "    cur.execute(\"CREATE TABLE {t} ({k});\".format(t=splitcsv, k=key_string)) #creates a new table for the sqlite file\n",
    "    \n",
    "    with open(csv_file,'rb') as fin: #inserts the data\n",
    "        dr = csv.DictReader(fin)\n",
    "        to_db = []\n",
    "        for i in dr:\n",
    "            row = []\n",
    "            for key in keys:\n",
    "                row.append(unicode(i[key], 'utf8'))\n",
    "            to_db.append(row)\n",
    "            \n",
    "    cur.executemany(\"INSERT INTO {t} ({k}) VALUES ({q});\".format(t=splitcsv, k=key_string, q=question_marks), to_db)\n",
    "    con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
